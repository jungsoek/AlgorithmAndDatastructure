# 3. 고급 자료구조 및 알고리즘

# 3.1 고급 트리 구조

## Splay Tree

### 📌 개념 정의

**Splay Tree**는 **이진 탐색 트리(BST)**의 일종으로, **삽입/삭제/탐색 이후마다 해당 노드를 루트로 끌어올리는 회전 연산(splaying)을 수행하는 트리**이다.

> 자주 접근되는 노드를 루트에 가깝게 유지하여, 전체 트리의 접근 시간 평균을 최적화한다.

### 🧠 핵심 개념: Splaying

- 특정 노드에 접근 후, 해당 노드를 루트로 올리는 과정
- **BST 성질 유지 + 자가 조정**
- **3가지 회전 유형** 사용: Zig, Zig-Zig, Zig-Zag

### 🔁 회전(Rotation) 패턴

#### 1️⃣ Zig (Single Rotation)

> 부모가 루트인 경우

```
        x
       /
      y       →       y
                x
```

#### 2️⃣ Zig-Zig (Double Rotation)

> x → y → z 형태로 연속된 왼쪽 or 오른쪽 자식

```
        z
       /
      y
     /
    x        →        x
                   \
                    y
                     \
                      z
```

#### 3️⃣ Zig-Zag (Double Rotation)

> x가 y의 오른쪽 자식, y는 z의 왼쪽 자식 (또는 반대)

```
        z
       /
      y
       \
        x       →        x
                      /     \
                     y       z
```

### 📊 연산 성능 분석

| 연산 | 시간 복잡도 (평균) | 최악 시간 복잡도 |
| ---- | ------------------ | ---------------- |
| 삽입 | O(log n)           | O(n)             |
| 삭제 | O(log n)           | O(n)             |
| 탐색 | O(log n)           | O(n)             |

✅ 하지만 **모든 연산 후 루트로 이동시키기 때문에, 자주 쓰이는 노드에 대해 접근 속도가 향상됨 (working set 효과)**
 ➡️ **전체 연산에 대한 시간복잡도는 O(m log n)** (m번 연산, n개의 노드)

### 🔧 C 스타일 노드 구조

```
typedef struct Node {
    int key;
    struct Node* left;
    struct Node* right;
} Node;
```

### ⚙️ 삽입 연산

1. 일반 BST 방식으로 삽입
2. 삽입된 노드를 루트로 **Splay**

### ⚙️ 탐색 연산

1. 찾고자 하는 노드를 BST 탐색
2. 탐색한 노드를 루트로 **Splay**

> 💡 탐색 실패 시, 마지막 탐색 노드를 루트로 올릴 수 있음

### ⚙️ 삭제 연산

1. 삭제할 노드를 탐색 후 Splay
2. 루트에서 제거 → 왼쪽 서브트리와 오른쪽 서브트리를 분리
3. 왼쪽 서브트리의 **최대 노드를 Splay** → 루트로
4. 오른쪽 서브트리를 오른쪽 자식으로 붙임

### 🧭 Splay Tree의 특징

| 특징             | 설명                                       |
| ---------------- | ------------------------------------------ |
| 자가 조정 트리   | 항상 루트가 최근 사용된 노드               |
| 균형 조건 없음   | AVL처럼 높이 균형을 유지하지 않음          |
| 중복 허용 불가   | BST 성질상 키는 유일                       |
| 반복 접근 최적화 | 자주 접근하는 키에 대해 O(1)에 가까운 성능 |
| 공간 효율 높음   | 균형 트리처럼 balance factor 없음          |

### ⚠️ Splay Tree vs AVL/Red-Black Tree

| 항목             | Splay Tree         | AVL / Red-Black Tree     |
| ---------------- | ------------------ | ------------------------ |
| 균형 유지        | X (암시적 유지)    | O (명시적 유지)          |
| 최악 시간복잡도  | O(n)               | O(log n)                 |
| 평균 시간복잡도  | O(log n)           | O(log n)                 |
| 구현 복잡도      | 낮음               | 높음                     |
| 자주 접근 최적화 | O(1) 수준으로 가능 | X                        |
| 메모리 추가 필요 | 없음               | 있음 (balance factor 등) |

### ✅ 언제 Splay Tree를 사용하나?

| 상황                                      | 이유                    |
| ----------------------------------------- | ----------------------- |
| 특정 키에 대한 **집중적 접근**이 잦을 때  | 루트로 스플레이됨       |
| 전체 범위보다 **일부분만 자주 조회**할 때 | working-set 최적화      |
| **균형 유지 부하 줄이고 싶을 때**         | AVL보다 간단            |
| 캐시, 텍스트 편집기, 페이지 히스토리 등   | 지역성 강한 작업에 적합 |

### 🧠 응용 사례

- 텍스트 편집기 undo/redo
- 메모리 할당기
- 가상 메모리 페이지 교체
- 디스크 블록 캐시
- 문자열 검색 (접두사 빈도 높은 경우)

### 💬 인터뷰에서 나올 수 있는 질문

- Splay Tree는 어떻게 균형을 유지하나요?
- AVL과 비교했을 때의 장점과 단점은?
- Splaying의 패턴을 설명해보세요.
- Splay Tree를 쓰면 항상 빠른가요?
- 재귀 아닌 iterative 구현이 가능한가요?

### 📌 정리 요약

| 특성        | 내용                             |
| ----------- | -------------------------------- |
| 트리 유형   | 이진 탐색 트리 (BST) 기반        |
| 특징        | 자주 접근하는 노드를 루트로 승격 |
| 회전 종류   | Zig, Zig-Zig, Zig-Zag            |
| 시간 복잡도 | O(log n) 평균, O(n) 최악         |
| 강점        | locality of reference 최적화     |
| 단점        | 최악 케이스가 많고 보장 없음     |
| 비교 대상   | AVL, Red-Black Tree, Treap       |

## Segment Tree with Lazy Propagation

### 📌 1. Segment Tree란?

- **세그먼트 트리**는 주어진 배열에 대해 **특정 구간의 정보를 빠르게 계산할 수 있는 트리 자료구조**
- `O(log n)` 시간 복잡도로 **구간 쿼리(query)**와 **점/구간 업데이트(update)** 처리 가능

```
예: [2, 1, 5, 3, 4]
- 쿼리: 구간 [1, 3]의 합 = 1 + 5 + 3 = 9
- 쿼리: 구간 [0, 4]의 최댓값
- 업데이트: 인덱스 2의 값을 10으로 변경
```

### 📦 2. 기본 Segment Tree 구조

- 보통 **2n 크기의 배열로 구현**
- **루트 = 전체 구간**, 자식은 왼쪽/오른쪽 절반을 의미
- 노드는 다음을 저장:
  - `start`, `end`: 구간 범위
  - `value`: 해당 구간의 정보 (합, 최댓값 등)

### 📉 기본 시간 복잡도

| 연산 유형   | 시간 복잡도 |
| ----------- | ----------- |
| 구간 쿼리   | O(log n)    |
| 점 업데이트 | O(log n)    |
| 전체 빌드   | O(n)        |

### ⚡ 문제점: 구간 업데이트 시 성능 저하

예를 들어, `[1, 10]` 구간에 모두 `+3` 하려면…

- 트리를 전부 내려가면서 자식 노드를 모두 수정해야 함 → **O(n)**

### 💡 해결책: Lazy Propagation (지연 업데이트)

> **필요할 때만 업데이트** 하자! (나중에 밀어두기)

- 변경 요청이 들어오면, **노드를 즉시 수정하지 않고 lazy 배열에 표시**
- 해당 노드에 접근할 때 **그제야 적용(push-down)**

### 🧠 핵심 아이디어 요약

| 구성 요소  | 설명                                      |
| ---------- | ----------------------------------------- |
| `tree[]`   | 구간 정보를 담는 세그먼트 트리 배열       |
| `lazy[]`   | "이 구간에 아직 반영 안 된 업데이트" 저장 |
| `push()`   | 자식 노드로 lazy 값을 전파                |
| `update()` | 구간 업데이트 요청 시 lazy에만 기록       |
| `query()`  | 쿼리 시 lazy 값 먼저 반영하고 처리        |

### 🔧 3. 구현 (C++ 버전 예시: 구간 합 트리)

```
const int MAX = 1 << 18;
int tree[MAX * 2];
int lazy[MAX * 2];

// 내부 노드에 lazy 값을 자식으로 전파
void push(int node, int l, int r) {
    if (lazy[node] != 0) {
        tree[node] += (r - l + 1) * lazy[node];
        if (l != r) {
            lazy[node * 2] += lazy[node];
            lazy[node * 2 + 1] += lazy[node];
        }
        lazy[node] = 0;
    }
}

// 구간 업데이트: [start, end] 구간에 val을 더하기
void update(int node, int l, int r, int start, int end, int val) {
    push(node, l, r);
    if (r < start || end < l) return; // 전혀 안 겹침
    if (start <= l && r <= end) {     // 완전히 포함
        lazy[node] += val;
        push(node, l, r);
        return;
    }
    int mid = (l + r) / 2;
    update(node * 2, l, mid, start, end, val);
    update(node * 2 + 1, mid + 1, r, start, end, val);
    tree[node] = tree[node * 2] + tree[node * 2 + 1];
}

// 구간 쿼리: [start, end] 구간의 합
int query(int node, int l, int r, int start, int end) {
    push(node, l, r);
    if (r < start || end < l) return 0;
    if (start <= l && r <= end) return tree[node];
    int mid = (l + r) / 2;
    return query(node * 2, l, mid, start, end) +
           query(node * 2 + 1, mid + 1, r, start, end);
}
```

> 위는 배열 [1, N]을 대상으로 segment tree + lazy propagation을 사용하는 구간 합 예시.

### 📊 시간 복잡도 (Lazy 적용 후)

| 연산          | 시간 복잡도 |
| ------------- | ----------- |
| 구간 쿼리     | O(log n)    |
| 구간 업데이트 | O(log n)    |
| 전체 초기화   | O(n)        |

### ✅ Lazy Propagation이 필요한 상황

| 문제 상황                               | Lazy 필요 여부                        |
| --------------------------------------- | ------------------------------------- |
| **점 업데이트만 있는 문제**             | ❌ 불필요 (기본 세그먼트 트리 suffice) |
| **구간 업데이트 + 구간 쿼리**           | ✅ 필수                                |
| **쿼리 수 ≫ 배열 크기 (많은 업데이트)** | ✅ 매우 유리                           |

### 🧠 확장 가능한 연산

Lazy Propagation은 다음과 같은 연산에서도 적용 가능:

- 구간 합, 구간 최솟값, 구간 최댓값
- 구간 곱셈
- **구간 전체 치환 (`arr[i] = X`)** ← lazy 값 1개가 아닌 트리 구조로 확장 필요
- 비트 마스킹, XOR, boolean 연산도 가능

### 💡 실전 알고리즘 문제 예시

| 문제 이름                           | 플랫폼    | 개념                  |
| ----------------------------------- | --------- | --------------------- |
| 구간 합 구하기 2                    | BOJ 10999 | lazy segment tree     |
| 수열과 쿼리 17                      | BOJ 14428 | min segment tree      |
| Count of Smaller Numbers After Self | Leetcode  | segment + compression |
| Range Addition                      | Leetcode  | 구간 update + lazy    |

### 💬 인터뷰에서 나올 수 있는 질문

- Lazy Propagation이 필요한 이유는?
- 세그먼트 트리와 펜윅 트리 차이점은?
- 구간 전체 값을 치환하는 경우 어떻게 lazy를 확장할 것인가?
- 동적 세그먼트 트리는 무엇이며 언제 쓰는가?

### 📌 요약 정리

| 항목             | 내용                                                     |
| ---------------- | -------------------------------------------------------- |
| 구조             | 완전 이진 트리 (배열로 표현)                             |
| 용도             | 구간 정보의 빠른 쿼리와 업데이트                         |
| Lazy Propagation | 지연 업데이트를 통해 성능 향상                           |
| 핵심 아이디어    | 필요할 때만 업데이트, 안 쓰면 O(n)                       |
| 시간복잡도       | O(log n) per query/update                                |
| 응용 분야        | 경쟁 프로그래밍, DB 업데이트, UI 업데이트, 시뮬레이션 등 |

## Treap

### 🧠 기본 개념

**주소지정 방식(Addressing Mode)**은 명령어 내 오퍼랜드가 실제 데이터를 어떻게 참조하는지를 나타내는 방식이야.

> 같은 명령어라도 주소지정 방식에 따라 **다른 위치의 데이터**를 사용할 수 있어.

### 🔩 주소지정 방식 종류 및 설명

| 방식                                                  | 설명                                 | 예시                                  |
| ----------------------------------------------------- | ------------------------------------ | ------------------------------------- |
| **1. 즉시 (Immediate)**                               | 오퍼랜드가 값 그 자체                | `MOV R1, #5` → R1 ← 5                 |
| **2. 레지스터 (Register)**                            | 오퍼랜드가 레지스터                  | `ADD R1, R2` → R1 ← R1 + R2           |
| **3. 직접 (Direct)**                                  | 명령어에 메모리 주소가 포함          | `MOV R1, [1000h]` → R1 ← MEM[1000h]   |
| **4. 간접 (Indirect)**                                | 레지스터가 주소를 가리킴             | `MOV R1, [R2]` → R1 ← MEM[R2]         |
| **5. 레지스터 간접 + 오프셋**                         | 베이스 + 변위 (offset)               | `MOV R1, [R2 + 4]`                    |
| **6. 인덱스 (Indexed)**                               | 배열 접근용 (베이스 + 인덱스 * 크기) | `MOV R1, [R2 + R3]`                   |
| **7. 상대 (PC-relative)**                             | 현재 위치 기준 주소                  | `JMP PC+8`                            |
| **8. 자동 증가/감소 (Auto-increment/Auto-decrement)** | 접근 후 주소 변화                    | `MOV R1, [R2++]`                      |
| **9. 스택 주소지정 (Implicit via SP)**                | PUSH/POP처럼 암묵적으로 SP 사용      | `PUSH R1` → SP ← SP - 4; MEM[SP] ← R1 |

### 🧪 각 방식 비교 예시

| 어셈블리 명령       | 주소지정 방식   | 의미                      |
| ------------------- | --------------- | ------------------------- |
| `MOV R1, #5`        | 즉시            | R1 ← 5                    |
| `MOV R1, R2`        | 레지스터        | R1 ← R2                   |
| `MOV R1, [1000h]`   | 직접            | R1 ← MEM[1000h]           |
| `MOV R1, [R2]`      | 간접            | R1 ← MEM[R2]              |
| `MOV R1, [R2 + 8]`  | 베이스 + 오프셋 | R1 ← MEM[R2+8]            |
| `MOV R1, [R2 + R3]` | 인덱스          | R1 ← MEM[R2 + R3]         |
| `JMP label`         | 상대            | PC ← PC + offset          |
| `LDR R1, [R2], #4`  | 자동 증가       | R1 ← MEM[R2], R2 ← R2 + 4 |

### 📐 실제 ISA별 주소지정 방식 요약

| ISA        | 지원 방식                     | 비고                       |
| ---------- | ----------------------------- | -------------------------- |
| **x86**    | 거의 모든 방식 지원           | 매우 유연하나 복잡         |
| **ARM**    | 즉시, 간접, 오프셋, PC 상대   | LDR/STR 계열에서 분리 지원 |
| **MIPS**   | 제한된 방식 (Base + Offset만) | Load/Store 전용 구조       |
| **RISC-V** | Base+Offset, PC-relative      | 단순하고 정형화된 구조     |

### 📊 시각적 비교 예시

```
명령어:   MOV R1, [R2 + 4]
설명:     R2는 기준 주소 (Base), 4는 오프셋
실제 동작: R1 ← 메모리 주소 (R2 + 4)의 값
```

### 🧠 주소지정 방식 선택 기준

| 목적              | 추천 방식                | 이유                 |
| ----------------- | ------------------------ | -------------------- |
| 상수 설정         | Immediate                | 빠르고 메모리 불필요 |
| 변수 간 연산      | Register                 | 고속                 |
| 구조체/배열 접근  | Base + Offset            | 필드 접근에 적합     |
| 함수 테이블       | 간접                     | 유연한 제어 흐름     |
| 루프 내 배열 순회 | Indexed / Auto-increment | 반복 접근에 최적     |

### 💬 고급 활용

| 기법                 | 사용 예                                |
| -------------------- | -------------------------------------- |
| **PC-relative**      | 실행 위치 독립 코드 (PIC, shared lib)  |
| **Auto-increment**   | 문자열 복사, 배열 순회                 |
| **Indirect + Index** | 2차원 배열, 가상 테이블 접근           |
| **SP-relative**      | 함수 로컬 변수 참조 (Stack Frame 기반) |

### 📌 요약 정리

- 주소지정 방식은 **오퍼랜드(피연산자)의 위치를 해석하는 방법**이다.
- 즉시, 레지스터, 직접, 간접, 베이스+오프셋, 인덱스, 상대, 자동 증가 등 다양한 방식이 존재하고, 목적에 따라 사용된다.
- 현대 ISA는 성능, 전력, 코드 크기 등을 고려해 주소지정 방식을 조합적으로 채택하고 있으며, 이 구조는 **명령어 효율성의 핵심 요소**다.

## B-Tree, B+ Tree (데이터베이스 용도)

> ✅ 데이터베이스와 파일 시스템 인덱스의 표준 구조

### 📌 1. B-Tree란?

**B-Tree**는 다진 트리(M-ary Tree)로,
 모든 리프 노드가 **동일한 깊이**에 있고,
 각 노드는 **여러 개의 키와 자식 포인터를 가짐**.

> 디스크 접근 횟수를 최소화하도록 설계된 **균형 검색 트리**

### 🧠 주요 특징

| 항목                | 설명                                          |
| ------------------- | --------------------------------------------- |
| 균형 유지           | 삽입/삭제 후에도 항상 균형 유지 (높이 유지됨) |
| 다진 구조           | 자식 수가 많아 한 노드에 여러 키 저장 가능    |
| 노드 크기           | 디스크 블록 크기에 맞춰 설정 (I/O 최소화)     |
| 정렬된 키 유지      | 중위 순회 시 오름차순 출력 가능               |
| 삽입/삭제/탐색 성능 | O(log n) (기수 m에 따라 더 빠름)              |

### 📌 2. B-Tree의 구조 (간단 예시)

```
예시: B-Tree of order 3 (최대 2키, 최대 3자식)

          [17]
        /     \
     [3, 8]   [20, 25]

각 노드는 다음을 가짐:
- 최대 m-1 개의 키
- 최대 m 개의 자식
- 키와 자식 사이 관계: [K1] → < K1, [K2] → < K2, ...
```

### 🔄 B-Tree 연산 (삽입/삭제 시)

- 삽입 시: 노드가 가득 차면 **분할(split)**
- 삭제 시: 노드가 너무 작아지면 **병합 또는 키 이동(rebalance)** 수행
- 항상 리프까지 도달해야 연산이 끝남

### 📌 3. B+ Tree란?

**B+ Tree**는 B-Tree의 변형으로,
 모든 **데이터(값)는 리프 노드에만 존재**,
 내부 노드는 **경로 탐색용 키만 보관**한다.

### 💡 핵심 차이점

| 항목             | B-Tree           | B+ Tree                                         |
| ---------------- | ---------------- | ----------------------------------------------- |
| 데이터 저장 위치 | 모든 노드에 있음 | **리프 노드에만 있음**                          |
| 범위 쿼리 효율   | 비효율적         | **리프 노드가 연결 리스트처럼 연결됨 → 효율적** |
| 리프 노드 연결   | 없음             | **있음 (→ 범위 조회 최적화)**                   |
| 내부 노드 역할   | 키 + 값 포함     | **키만 존재 (인덱싱 역할만)**                   |

### 🧠 B+ Tree의 구조 (예시)

```
              [17, 25]
              /      \
          [5, 8, 12] [17, 20, 24]

리프 노드:
[5] → [8] → [12] → [17] → [20] → [24]
(← 모든 실제 데이터는 여기만 저장)
```

### ⏱️ 성능 비교 요약

| 연산          | B-Tree   | B+ Tree                             |
| ------------- | -------- | ----------------------------------- |
| 검색          | O(log n) | O(log n)                            |
| 삽입/삭제     | O(log n) | O(log n)                            |
| **범위 검색** | 느림     | **빠름 (리프 연결)**                |
| I/O 적중률    | 중간     | **높음** (내부 노드 작은 크기 유지) |
| 캐시 효율성   | 낮음     | **높음**                            |

### 🧭 왜 데이터베이스에서 B+ Tree를 쓸까?

| 이유                           | 설명                                                    |
| ------------------------------ | ------------------------------------------------------- |
| 범위 쿼리에 최적화             | `BETWEEN`, `LIKE`, `>`, `<` 처리 성능 우수              |
| 디스크 블록 단위 정렬 유지     | 리프 노드가 연결된 덕분에 **정렬된 순서 유지**          |
| 높은 가지 수(branching factor) | 트리의 **높이를 줄여 디스크 I/O 감소**                  |
| 내부 노드 캐싱 용이            | 값 없이 키만 존재 → **메모리에 더 많은 노드 유지 가능** |
| InnoDB 클러스터 인덱스 구조    | MySQL에서 PK 인덱스를 B+ Tree로 구현함                  |

### 📂 InnoDB (MySQL)의 B+ Tree 실제 사용 예시

- **PK (기본키)**: 클러스터 인덱스, 실제 데이터 포함한 리프 노드
- **보조 인덱스(Secondary Index)**: 리프 노드에는 PK 주소만 저장
- 모든 인덱스는 B+ Tree로 구성됨

### 💬 인터뷰에서 나올 수 있는 질문

- B-Tree와 B+ Tree의 차이점은?
- 왜 데이터베이스는 B+ Tree를 사용하나요?
- B+ Tree에서 삽입 시 발생하는 구조적 변화는?
- 범위 검색 시 B+ Tree가 효율적인 이유는?

### 📌 정리 요약

| 항목        | B-Tree                   | B+ Tree                                       |
| ----------- | ------------------------ | --------------------------------------------- |
| 데이터 위치 | 내부/리프 모두           | 리프에만 존재                                 |
| 범위 쿼리   | 느림                     | 빠름 (리프 연결 리스트 구조)                  |
| 디스크 I/O  | 더 많음                  | **최적화됨** (높이 낮고 정렬 유지)            |
| 검색 속도   | logₘN                    | logₘN                                         |
| 사용 분야   | 과거 DB, 일부 파일시스템 | **현대 RDBMS, InnoDB, Oracle, PostgreSQL 등** |

# 3.2 고급 그래프 알고리즘

## 최소 비용 유량(Min-Cost Max Flow)

### 📌 1. 문제 정의

**주어진 유량 그래프**에서

- 각 간선에는 **용량(capacity)**과 **비용(cost)**이 존재하고
- 시작점에서 종료점으로 보낼 수 있는 **최대 유량(flow)**을 구하되,
- **총 비용의 합이 최소**가 되도록 한다.

### 🔢 2. 모델링 요소

| 항목             | 의미                               |
| ---------------- | ---------------------------------- |
| 정점 `V`         | 노드들 (공장, 창고, 소비지 등)     |
| 간선 `E`         | 흐를 수 있는 경로                  |
| `capacity(u, v)` | 간선(u→v)의 최대 유량              |
| `cost(u, v)`     | 1단위 유량이 u→v로 갈 때 드는 비용 |
| `flow(u, v)`     | 실제 흐르는 유량                   |

> 목표:
>
> - `∑ flow = 최대`
> - `∑ cost × flow = 최소`

### 🔁 3. 해결 전략

#### 핵심 아이디어:

**최소 비용의 경로로 유량을 보내고**,
 더 이상 보낼 수 없을 때까지 반복한다.

#### 알고리즘 구성:

1. 유량이 남아 있는 그래프에서 **최소 비용 경로**를 찾는다.
2. **그 경로로 가능한 만큼 유량을 보낸다.**
3. 잔여 용량을 업데이트하고 1번 반복.

### 🧠 핵심 알고리즘 구성 요소

| 개념                            | 설명                                                         |
| ------------------------------- | ------------------------------------------------------------ |
| **잔여 그래프(Residual Graph)** | 간선의 남은 용량과 역방향 흐름을 표현하는 그래프             |
| **역방향 간선(back edge)**      | 유량을 되돌리는 간선, 비용은 음수                            |
| **최단 경로 탐색**              | Dijkstra (음수 비용 없을 경우), Bellman-Ford (음수 비용 허용) |
| **SPFA**                        | Bellman-Ford의 큐 기반 최적화 버전                           |

### 📊 시간 복잡도 (Dijkstra + Potential 사용 시)

- Dijkstra × O(F × E log V)
   (F: 최대 유량, E: 간선 수, V: 정점 수)

### 🧮 예제 시나리오

#### 🎯 목표:

공장에서 고객에게 물건을 운반할 때

- 운반 경로마다 운송 비용 존재
- 제한된 물량만 운송 가능
   → 가장 싸게 최대한 많이 보내기

```
source --(capacity=5, cost=2)--> A --(5, 1)--> sink
        \                        /
         --(3, 4)--> B --(3, 1)--
```

> 목표: source → sink로 최대 유량을 보내되, 총 비용 최소

### 🧩 알고리즘 예시 (SPFA 버전의 Min-Cost Max Flow)

```
struct Edge {
    int to, rev;
    int cap, cost;
};

vector<Edge> graph[MAX];
int dist[MAX], prevv[MAX], preve[MAX];

void addEdge(int from, int to, int cap, int cost) {
    graph[from].push_back({to, (int)graph[to].size(), cap, cost});
    graph[to].push_back({from, (int)graph[from].size() - 1, 0, -cost});
}

int minCostMaxFlow(int s, int t, int& totalCost) {
    int flow = 0;
    totalCost = 0;
    const int INF = 1e9;

    while (true) {
        fill(dist, dist + MAX, INF);
        dist[s] = 0;
        bool inQueue[MAX] = {};
        queue<int> q;
        q.push(s);

        while (!q.empty()) {
            int v = q.front(); q.pop();
            inQueue[v] = false;
            for (int i = 0; i < graph[v].size(); ++i) {
                Edge& e = graph[v][i];
                if (e.cap > 0 && dist[e.to] > dist[v] + e.cost) {
                    dist[e.to] = dist[v] + e.cost;
                    prevv[e.to] = v;
                    preve[e.to] = i;
                    if (!inQueue[e.to]) {
                        q.push(e.to);
                        inQueue[e.to] = true;
                    }
                }
            }
        }

        if (dist[t] == INF) break;

        // 가능한 유량만큼 보내기
        int d = INF;
        for (int v = t; v != s; v = prevv[v])
            d = min(d, graph[prevv[v]][preve[v]].cap);
        flow += d;
        totalCost += d * dist[t];
        for (int v = t; v != s; v = prevv[v]) {
            Edge& e = graph[prevv[v]][preve[v]];
            e.cap -= d;
            graph[v][e.rev].cap += d;
        }
    }
    return flow;
}
```

### ✅ 실전에서 사용하는 알고리즘

| 방법                             | 특징                                        |
| -------------------------------- | ------------------------------------------- |
| Bellman-Ford                     | 음수 비용 가능, 느림                        |
| SPFA                             | Bellman-Ford 최적화, 보통 빠름              |
| Dijkstra + Potential (Johnson’s) | 비용이 음수 없거나 조정 가능할 때 매우 빠름 |

### 💡 실전 응용 사례

| 분야          | 예시                                  |
| ------------- | ------------------------------------- |
| 물류 최적화   | 최소 비용으로 트럭 물량 분배          |
| 작업 스케줄링 | 최소 인건비로 작업 할당               |
| 공정 제어     | 최대 처리량 확보하며 전력 비용 최소화 |
| 전력망 분배   | 최대 전송량 + 최소 송전 비용          |
| 네트워크 QoS  | 대역폭 최대 확보 + 비용 최소          |
| 대학 배정     | 정원 고려 + 만족도 기반 배정          |

### 💬 인터뷰/문제 풀이에서 나올 수 있는 질문

- 유량 문제에서 비용까지 고려하는 이유는?
- SPFA 방식과 Dijkstra 방식의 차이는?
- 잔여 그래프란?
- 왜 역방향 간선에 음수 비용을 두는가?
- Min-Cost Flow는 언제 종료되는가?

### 📌 요약

| 항목                  | 내용                                    |
| --------------------- | --------------------------------------- |
| 목표                  | 최대 유량, 최소 비용                    |
| 핵심 알고리즘         | 최단 경로 기반 유량 증대 반복           |
| 잔여 용량/역방향 간선 | 필수                                    |
| 성능                  | O(F × E log V) 정도                     |
| 실제 활용도           | 매우 높음 (물류, 네트워크, 스케줄링 등) |

## 최대 유량 (Ford-Fulkerson, Edmonds-Karp)

### 📌 문제 정의

**유량 네트워크**에서 **시작점(source)**에서 **종료점(sink)**까지
 흐를 수 있는 **최대 유량의 양**을 구하는 것이 목적.

> ⚠️ 각 간선에는 **용량(capacity)**이 있고, 이를 넘을 수는 없어

### 📦 그래프 구성 요소

| 항목            | 설명                     |
| --------------- | ------------------------ |
| 정점(V)         | 노드들 (공장, 송신기 등) |
| 간선(E)         | 흐름이 가능한 경로       |
| `capacity(u,v)` | 간선(u→v)의 최대 유량    |
| `flow(u,v)`     | 실제 흐르는 유량         |

> 목적:
>
> - `flow`는 `capacity`를 넘지 않아야 하며
> - 각 정점에서는 유입 = 유출 (`source`, `sink` 제외)

### 🔁 기본 전략: Ford-Fulkerson 방법

1. 유량을 0으로 초기화
2. **잔여 용량(residual capacity)이 있는 경로**를 찾아 유량을 더함
3. **반복** → 더 이상 augmenting path가 없을 때 종료

### 🔁 잔여 그래프(Residual Graph)

- 간선의 **남은 용량**을 나타내는 그래프
- 모든 간선에 대해 **역방향 간선도 존재** (flow 되돌리기 가능)

```
edge(u → v), capacity=5, flow=3 → residual=2
→ 역방향 edge(v → u) with capacity=3
```

### 🧠 Edmonds-Karp 알고리즘

Ford-Fulkerson의 특수한 구현:
 매번 **BFS로 가장 짧은 경로**를 선택

- **시간 복잡도**: O(V × E²)
- 유량이 증가하는 과정이 안정적이며, 무한 루프 방지

### 🔧 C++ 예제 코드 (Edmonds-Karp)

```
const int INF = 1e9;
int capacity[MAX][MAX], flow[MAX][MAX];
vector<int> graph[MAX];

int bfs(int s, int t, vector<int>& parent) {
    fill(parent.begin(), parent.end(), -1);
    parent[s] = s;
    queue<pair<int, int>> q;
    q.push({s, INF});

    while (!q.empty()) {
        int cur = q.front().first;
        int f = q.front().second;
        q.pop();

        for (int next : graph[cur]) {
            if (parent[next] == -1 && capacity[cur][next] - flow[cur][next] > 0) {
                parent[next] = cur;
                int new_flow = min(f, capacity[cur][next] - flow[cur][next]);
                if (next == t) return new_flow;
                q.push({next, new_flow});
            }
        }
    }
    return 0;
}

int maxFlow(int s, int t) {
    int total_flow = 0;
    vector<int> parent(MAX);
    int new_flow;

    while ((new_flow = bfs(s, t, parent))) {
        total_flow += new_flow;
        int cur = t;
        while (cur != s) {
            int prev = parent[cur];
            flow[prev][cur] += new_flow;
            flow[cur][prev] -= new_flow;
            cur = prev;
        }
    }
    return total_flow;
}
```

### 📊 시간 복잡도 비교

| 알고리즘             | 시간복잡도                   |
| -------------------- | ---------------------------- |
| Ford-Fulkerson (DFS) | O(E × maxFlow)               |
| Edmonds-Karp (BFS)   | O(V × E²)                    |
| Dinic                | O(E × V²), 일부 경우 O(√V E) |

### 💡 예제 문제

> ⚙️ “네트워크가 주어질 때, source → sink로 보낼 수 있는 최대 유량을 구하라”

#### 예시 입력:

```
4 nodes, source=0, sink=3

Edges:
0 → 1 (capacity: 10)
0 → 2 (capacity: 5)
1 → 2 (capacity: 15)
1 → 3 (capacity: 10)
2 → 3 (capacity: 10)
```

#### 정답:

- 가능한 유량:
  - 0 → 1 → 3: 10
  - 0 → 2 → 3: 5
     → 최대 유량: **15**

### 📚 활용 사례

| 분야          | 설명                                   |
| ------------- | -------------------------------------- |
| 네트워크 설계 | 데이터/전력 최적 분배                  |
| 물류 최적화   | 경로별 제한 고려한 물량 분배           |
| 이미지 세분화 | 그래프 컷 기반 분리                    |
| 이분 매칭     | 사람과 작업 매칭, 헝가리 알고리즘 연계 |
| 대회 알고리즘 | MCMF, Matching, Dinic 기반 문제들      |

### 💬 자주 나오는 질문

- Ford-Fulkerson과 Edmonds-Karp의 차이는?
- 역방향 간선이 왜 필요한가?
- 유량 보존 조건이란?
- 잔여 용량 그래프란 무엇인가?
- 이분 매칭 문제를 최대 유량으로 바꾸는 방법은?

### ✅ 요약

| 항목        | 설명                                        |
| ----------- | ------------------------------------------- |
| 입력        | 정점 수, 간선, 용량                         |
| 출력        | 시작점에서 끝점으로 보낼 수 있는 최대 유량  |
| 핵심 구성   | 잔여 용량, augmenting path, 역방향 간선     |
| 구현 방식   | DFS, BFS, Dinic                             |
| 최적화 기법 | BFS + 레벨 그래프 (Dinic), 용량 스케일링 등 |

## Strongly Connected Components (Tarjan, Kosaraju)

### 📌 1. 개념 정의

**강한 연결 요소(SCC, Strongly Connected Component)**란
 **유향 그래프**에서 **어떤 두 정점 u, v가 서로 도달 가능한** 최대 정점 집합을 말한다.

즉,

- `u → v`
- `v → u`
   → **양방향 도달 가능**한 정점끼리 묶인 집합이 SCC

### 📎 2. 예시

```
A → B → C → A     → SCC #1: {A, B, C}
D → E             → SCC #2: {D}, SCC #3: {E}
```

각 SCC는 **서로 다른 DAG(비순환 그래프)**의 노드처럼 연결된다.

### 📊 3. SCC의 성질

| 특성                     | 설명                                         |
| ------------------------ | -------------------------------------------- |
| 유향 그래프에서만 정의됨 | 무방향 그래프는 모든 연결 요소가 SCC         |
| 그래프 압축 가능         | SCC들을 하나의 노드로 취급하면 DAG 구조가 됨 |
| 위상 정렬 가능           | SCC 압축 그래프는 항상 DAG이므로 가능        |

### 🔍 4. SCC 탐색 알고리즘 2가지

| 알고리즘     | 특징                                                   |
| ------------ | ------------------------------------------------------ |
| **Tarjan**   | DFS 기반, **스택 + 시간 관리**, 한 번의 DFS로 SCC 추출 |
| **Kosaraju** | 2-pass DFS: 역방향 그래프 + 후위순으로 SCC 탐색        |

### 🔧 5. Tarjan’s Algorithm (단일 DFS 기반)

#### 🧠 핵심 개념

- 각 정점에 대해 **DFS 방문 순서 (id)** 기록
- **low-link**: 자신 또는 하위 노드 중 가장 빠른 방문 순서
- DFS 과정 중 **자기 자신으로 돌아올 수 있는지 판단**
- **스택을 이용한 탐색 경로 관리**

#### 🧩 핵심 흐름

1. DFS로 방문하며 `id`, `low-link` 갱신
2. 스택에 push
3. `id == low-link`일 때 → SCC 추출 (스택에서 pop)

#### ✅ C++ 코드 예시 (Tarjan)

```
vector<int> graph[MAX];
bool onStack[MAX];
int id[MAX], low[MAX], sccId[MAX], nodeId = 0, sccCount = 0;
stack<int> st;

void dfs(int u) {
    id[u] = low[u] = nodeId++;
    st.push(u); onStack[u] = true;

    for (int v : graph[u]) {
        if (id[v] == -1) {
            dfs(v);
            low[u] = min(low[u], low[v]);
        } else if (onStack[v]) {
            low[u] = min(low[u], id[v]);
        }
    }

    if (id[u] == low[u]) {
        while (true) {
            int v = st.top(); st.pop();
            onStack[v] = false;
            sccId[v] = sccCount;
            if (v == u) break;
        }
        sccCount++;
    }
}
```

- 전체 DFS 실행:

```
memset(id, -1, sizeof(id));
for (int i = 0; i < n; ++i)
    if (id[i] == -1) dfs(i);
```

### 🔄 6. Kosaraju’s Algorithm (2-pass DFS)

#### 🧠 핵심 흐름

1. **원래 그래프에서 DFS 수행 → 정점 후위 순서 기록**
2. **그래프의 모든 간선을 뒤집음 (transpose graph)**
3. 후위 순서대로 **역방향 그래프에 대해 DFS** 수행
4. 각 DFS 호출이 하나의 SCC가 됨

#### ✅ 장점

- 직관적이고 구현 간단
- 두 번의 DFS로 SCC 도출 가능

#### ✅ Kosaraju 코드 흐름

```
vector<int> graph[MAX], revGraph[MAX], order;
bool visited[MAX];
vector<vector<int>> sccs;

void dfs1(int u) {
    visited[u] = true;
    for (int v : graph[u])
        if (!visited[v]) dfs1(v);
    order.push_back(u);
}

void dfs2(int u, vector<int>& scc) {
    visited[u] = true;
    scc.push_back(u);
    for (int v : revGraph[u])
        if (!visited[v]) dfs2(v, scc);
}

void kosaraju(int n) {
    fill(visited, visited + n, false);
    for (int i = 0; i < n; i++)
        if (!visited[i]) dfs1(i);

    fill(visited, visited + n, false);
    reverse(order.begin(), order.end());

    for (int u : order) {
        if (!visited[u]) {
            vector<int> scc;
            dfs2(u, scc);
            sccs.push_back(scc);
        }
    }
}
```

### 📦 7. 사용 사례

| 분야                   | 설명                  |
| ---------------------- | --------------------- |
| 순환 의존성 분석       | 컴파일러 모듈, 패키지 |
| 회로 최적화            | 순환 루프 제거        |
| 상태기계 분석          | 상태 순환 탐지        |
| 웹 크롤러, 그래프 압축 | 연결된 사이트 그룹화  |
| 소셜 네트워크 분석     | 강한 영향 그룹 탐색   |

### 💬 자주 나오는 질문

- DFS로 SCC를 찾을 수 있는 이유는?
- low-link가 의미하는 것은?
- Tarjan과 Kosaraju의 차이점은?
- SCC를 DAG로 압축하면 어떤 이점이 있나?
- SCC를 기반으로 위상 정렬하려면?

### 📌 요약 정리

| 항목       | 내용                                               |
| ---------- | -------------------------------------------------- |
| 정의       | 모든 정점이 서로 도달 가능한 서브그래프            |
| 조건       | u→v, v→u 모두 가능해야 함                          |
| 알고리즘   | Tarjan(DFS), Kosaraju(2-pass)                      |
| 시간복잡도 | O(V + E) (둘 다 동일)                              |
| 활용       | 순환 탐지, 위상 정렬, 컴파일러 최적화, 그래프 압축 |

## Heavy-Light Decomposition (HLD)

### 📌 1. 개요

**HLD**는 트리 구조를 **heavy edge와 light edge로 나눠서**,
 트리의 경로를 **작은 개수의 세그먼트로 분해**해주는 자료구조 기법이다.

> 목적:
>  **트리의 두 노드 사이 경로에 대한 쿼리/업데이트**를 `O(log n)`에 처리 가능하게 한다.

### 🔍 2. 해결하려는 문제 예시

- **u ~ v 경로의 최댓값/합**
- **트리 경로의 XOR 계산**
- **서브트리 쿼리**
- **경로상의 노드 개수, 조건 만족 노드 수 등**

보통 단순 트리 탐색으로는 처리 불가능하거나 느린 문제를
 → HLD + 세그먼트 트리 조합으로 해결

### 🧠 3. 핵심 아이디어 요약

1. 트리의 간선/자식 중 **가장 큰 서브트리로 향하는 간선**을 `heavy edge`로 지정
2. 나머지 간선은 `light edge`로 둔다
3. 트리를 **heavy path들로 분해**해서 **세그먼트 트리 인덱스**를 지정한다
4. 쿼리를 **경로 구간 쿼리로 환원**시켜 세그먼트 트리로 처리

### 📐 4. 용어 정리

| 용어              | 설명                                      |
| ----------------- | ----------------------------------------- |
| **heavy edge**    | 자식 중 서브트리 크기가 가장 큰 간선      |
| **light edge**    | 나머지 자식으로 향하는 간선               |
| **chain**         | 연속된 heavy edge들로 구성된 경로         |
| **head**          | 각 체인의 시작점 노드                     |
| **in[node]**      | 노드가 세그먼트 트리 상에 매핑되는 인덱스 |
| **parent[node]**  | 부모 노드                                 |
| **depth[node]**   | 루트로부터의 깊이                         |
| **subsize[node]** | 서브트리 크기                             |

### 🔧 5. HLD 구현 절차 요약

1️⃣ **DFS1: 서브트리 크기 계산 + heavy child 지정**

```
void dfs1(int u, int p) {
    parent[u] = p;
    subsize[u] = 1;
    int maxSub = -1;

    for (int v : tree[u]) {
        if (v == p) continue;
        depth[v] = depth[u] + 1;
        dfs1(v, u);
        subsize[u] += subsize[v];
        if (subsize[v] > maxSub) {
            maxSub = subsize[v];
            heavy[u] = v;
        }
    }
}
```

2️⃣ **DFS2: 체인 분할 + 세그먼트 트리 인덱스 부여**

```
void dfs2(int u, int h) {
    head[u] = h;
    in[u] = curPos++; // 세그먼트 트리 인덱스
    if (heavy[u] != -1) dfs2(heavy[u], h); // 같은 체인 계속

    for (int v : tree[u]) {
        if (v != parent[u] && v != heavy[u])
            dfs2(v, v); // 새로운 체인 시작
    }
}
```

### 🔁 6. 경로 쿼리 처리 방식

```
int query(int u, int v) {
    int res = 0;
    while (head[u] != head[v]) {
        if (depth[head[u]] < depth[head[v]]) swap(u, v);
        res += seg.query(in[head[u]], in[u]);
        u = parent[head[u]];
    }
    if (depth[u] > depth[v]) swap(u, v);
    res += seg.query(in[u], in[v]); // 같은 체인
    return res;
}
```

### 🧮 시간 복잡도

| 연산               | 시간                                            |
| ------------------ | ----------------------------------------------- |
| 전처리             | O(N) (두 번의 DFS)                              |
| 경로 쿼리/업데이트 | O(log² N) (log N 체인 수 × log N 세그먼트 트리) |
| 서브트리 쿼리      | O(log N)                                        |

### 🏹 경로 쿼리 vs 서브트리 쿼리

| 쿼리 종류         | 대응 방식                                    |
| ----------------- | -------------------------------------------- |
| u ~ v 경로 쿼리   | HLD 체인 jump + 세그먼트 쿼리                |
| u의 서브트리 쿼리 | `in[u] ~ out[u]`로 처리 (별도 DFS 시간 기록) |

### 📚 활용 문제 유형

| 문제 유형                     | HLD 활용 여부 |
| ----------------------------- | ------------- |
| 트리 경로 쿼리 (합, 최대 등)  | ✅ 필수        |
| LCA를 활용한 경로 분할 문제   | ✅ 자주 쓰임   |
| 트리 위에 Binary Indexed Tree | ✅ 구조 유사   |
| centroid decomposition        | ❌ 다른 방식   |

### 💬 인터뷰/실전 질문

- HLD의 목적은 무엇인가요?
- 어떻게 경로를 분해하나요?
- 왜 세그먼트 트리를 쓰나요?
- 경로 쿼리를 log² N에 하는 이유는?

### ✅ 정리 요약

| 항목          | 설명                                           |
| ------------- | ---------------------------------------------- |
| 목적          | 트리 경로 쿼리를 빠르게 처리                   |
| 방식          | 트리를 heavy path로 분해 후 세그먼트 트리 매핑 |
| 핵심 자료구조 | 세그먼트 트리, in[], head[], parent[]          |
| 시간복잡도    | O(log² N) 경로 쿼리                            |
| 응용          | 트리 쿼리, 트리 다이나믹, 네트워크             |

# 3.3 문자열 알고리즘

## KMP 알고리즘

### 📌 1. 문제 정의

> **주어진 텍스트 T에서, 패턴 P가 처음 등장하는 위치(들)를 O(N) 시간에 찾아라.**

#### ❌ 브루트포스의 한계

기존의 naive 방식은:

- 일치하지 않으면 패턴을 **한 칸 뒤로 밀고 처음부터 다시 비교**
- 최악의 경우 `O(NM)` (텍스트 길이 N, 패턴 길이 M)

```
T = abababababc
P = abababc
```

패턴이 겹치는 구조일수록 반복 비교가 많아짐 → 비효율

### ✅ KMP의 핵심 아이디어

> "일치하던 부분은 **다시 비교하지 않아도 된다**!"

#### ✨ 핵심:

**접두사 == 접미사**인 구조를 이용해,
 **실패했던 부분까지의 정보**를 활용하여 **패턴을 점프**함.

### 🧠 핵심 구성

| 구성 요소       | 설명                                |
| --------------- | ----------------------------------- |
| `T` (텍스트)    | 전체 문자열 (길이 N)                |
| `P` (패턴)      | 찾고자 하는 부분 문자열 (길이 M)    |
| **LPS 배열**    | 패턴의 접두사/접미사 일치 정보 저장 |
| 비교 인덱스 `i` | 텍스트 위치                         |
| 비교 인덱스 `j` | 패턴 위치                           |

### 📦 LPS 배열 (Longest Prefix Suffix)

> `lps[i]`: 패턴 P의 [0...i] 구간에서, **접두사 == 접미사**의 최대 길이

#### 예시:

```
P = a b a b a c

i    : 0 1 2 3 4 5
lps  : 0 0 1 2 3 0
```

#### 의미:

- `lps[4] = 3` → `abab`의 접두사/접미사 공통 길이는 `aba`

### 🔧 LPS 배열 구성 코드

```
vector<int> computeLPS(string P) {
    int M = P.length();
    vector<int> lps(M, 0);
    int len = 0; // 이전 접두사 길이

    for (int i = 1; i < M; ++i) {
        while (len > 0 && P[i] != P[len])
            len = lps[len - 1];

        if (P[i] == P[len]) lps[i] = ++len;
    }
    return lps;
}
```

### 🔍 검색 단계

1. `i=0`, `j=0`부터 시작
2. `T[i] == P[j]` → 둘 다 증가
3. `T[i] ≠ P[j]` → `j = lps[j-1]`로 점프
4. `j == M` → 패턴 전체 일치 → 위치 기록

### 🔧 전체 KMP 검색 코드 (C++)

```
vector<int> kmpSearch(string T, string P) {
    vector<int> lps = computeLPS(P);
    vector<int> matches;
    int i = 0, j = 0;
    int N = T.size(), M = P.size();

    while (i < N) {
        if (T[i] == P[j]) {
            i++; j++;
        }

        if (j == M) {
            matches.push_back(i - j);
            j = lps[j - 1]; // 다음 검색
        } else if (i < N && T[i] != P[j]) {
            if (j != 0) j = lps[j - 1];
            else i++;
        }
    }

    return matches;
}
```

### ⏱️ 시간 복잡도

| 단계       | 복잡도       |
| ---------- | ------------ |
| LPS 전처리 | O(M)         |
| 검색       | O(N)         |
| 전체       | **O(N + M)** |

→ 문자열 전체 길이에 비례한 **선형 시간 검색**

### 📚 KMP 알고리즘의 활용 분야

| 분야                    | 설명                       |
| ----------------------- | -------------------------- |
| 텍스트 에디터 검색 기능 | 빠른 문자열 찾기           |
| DNA 서열 분석           | 유전자 서열 부분 매칭      |
| 네트워크 패킷 검사      | 특정 문자열 포함 여부 검사 |
| 로그 분석, 필터링       | 패턴 일치 필터링           |
| 반복 패턴 탐지          | `ababab` 같은 규칙 탐색    |

### 💬 인터뷰/시험 질문

- KMP와 브루트포스 방식의 차이는?
- LPS 배열의 의미는?
- KMP가 O(NM)으로 느려질 수 있나?
- KMP에서 역방향 검색은 가능한가?

### ✅ 정리 요약

| 항목          | 설명                                   |
| ------------- | -------------------------------------- |
| 목표          | 텍스트 T에서 패턴 P를 선형 시간에 찾기 |
| 핵심 구조     | LPS 배열 (접두사 = 접미사 길이)        |
| 알고리즘 흐름 | 전처리 → 검색 (점프)                   |
| 시간복잡도    | O(N + M)                               |
| 주요 특징     | 텍스트 재탐색 없음, 공간 효율적        |

## Z-Algorithm

### 📌 1. 문제 정의

**주어진 문자열 `S`에 대해, 각 위치에서 시작하는 접미사가 얼마나 앞에서와 일치하는지를 나타내는 배열 Z를 계산하라.**

- `Z[i]`: 문자열 `S[i:]`와 `S[0:]`이 몇 글자나 일치하는가?

```
S = a b a b a c a b a b a b
Z = 0 0 1 0 3 0 1 0 5 0 1 0
```

### 🧠 2. 핵심 개념

- `Z[0]`은 의미 없음 (보통 0으로 정의)
- Z-배열은 **S에서의 각 위치 i부터 시작한 접미사와 S[0:]의 최대 일치 길이**를 의미

> Z[i] = max k such that S[0:k] == S[i:i+k]

### 💡 3. Z배열로 가능한 일

| 활용                             | 설명                                          |
| -------------------------------- | --------------------------------------------- |
| 문자열 검색                      | `P + "$" + T`를 만들어 Z배열로 일치 위치 탐색 |
| 반복 패턴 탐지                   | Z[i] + i == N → 패턴 전체 반복                |
| 문자열의 접두사/접미사 구조 분석 | 접두사로도 쓰이는 접미사 탐지                 |

### 📦 4. Z배열 계산 알고리즘

> **[l, r]** 구간을 유지하면서, 현재 위치 `i`가 그 안에 있다면 기존 값을 재활용
>  → `O(N)`에 계산 가능

#### ✅ 코드 (C++)

```
vector<int> getZ(string s) {
    int n = s.size();
    vector<int> Z(n);
    int l = 0, r = 0;

    for (int i = 1; i < n; ++i) {
        if (i <= r)
            Z[i] = min(r - i + 1, Z[i - l]);

        while (i + Z[i] < n && s[Z[i]] == s[i + Z[i]])
            Z[i]++;

        if (i + Z[i] - 1 > r) {
            l = i;
            r = i + Z[i] - 1;
        }
    }
    return Z;
}
```

### 🧪 5. 문자열 검색 (패턴 찾기)

```
P = abab
T = abababab

→ S = P + "$" + T = abab$abababab
→ Z배열 계산 후 Z[i] == P.length() 인 지점이 매칭 지점
```

```
vector<int> search(string P, string T) {
    string S = P + "$" + T;
    vector<int> Z = getZ(S);
    vector<int> matches;
    int lenP = P.size();

    for (int i = lenP + 1; i < S.size(); ++i) {
        if (Z[i] == lenP)
            matches.push_back(i - lenP - 1);
    }
    return matches;
}
```

### ⏱️ 6. 시간 복잡도

| 연산        | 시간복잡도                   |
| ----------- | ---------------------------- |
| Z배열 계산  | **O(N)**                     |
| 문자열 검색 | **O(N + M)** (패턴 + 텍스트) |

### 📚 7. Z vs KMP

| 항목          | KMP                   | Z 알고리즘                    |
| ------------- | --------------------- | ----------------------------- |
| 핵심 자료구조 | LPS 배열              | Z 배열                        |
| 비교 기준     | 패턴 내의 접두사 일치 | **문자열 전체의 접두사 일치** |
| 전처리 대상   | 패턴(P)만             | 패턴 + 텍스트 (합친 문자열)   |
| 사용 패턴     | 부분일치 점프용       | 접두사 분석, 일치 지점 파악   |
| 코드 복잡도   | 약간 복잡             | 더 직관적                     |

### 🧠 8. 실전 활용 예시

| 문제 유형                     | Z 활용               |
| ----------------------------- | -------------------- |
| 패턴 일치 검색                | ✅                    |
| 문자열 압축/반복 탐지         | ✅                    |
| 접두사와 접미사 관계          | ✅                    |
| 여러 패턴 검색 (Aho-Corasick) | ❌ 다른 알고리즘 사용 |

### 💬 인터뷰 질문

- Z[i]가 의미하는 것은?
- Z배열을 어떻게 O(N)에 계산할 수 있나?
- KMP와 Z의 차이점은?
- 문자열 T에서 P가 등장하는 모든 위치를 Z를 이용해 구하는 방법은?

### ✅ 정리 요약

| 항목       | 설명                                         |
| ---------- | -------------------------------------------- |
| Z[i]       | S[0:]와 S[i:]의 접두사 일치 길이             |
| 목적       | 문자열 일치, 반복 분석                       |
| 시간복잡도 | O(N)                                         |
| 주요 응용  | 문자열 검색, 반복 패턴 탐지                  |
| 장점       | KMP보다 간단한 구현, 다양한 접두사 응용 가능 |

## Suffix Array / Suffix Tree

### 📌 1. 핵심 개념

| 개념             | 설명                                                         |
| ---------------- | ------------------------------------------------------------ |
| **Suffix**       | 문자열의 접미사. 예: `banana`의 suffix는 `banana`, `anana`, `nana`, `ana`, `na`, `a` |
| **Suffix Array** | 모든 접미사를 **사전순 정렬한 인덱스 배열**                  |
| **Suffix Tree**  | 모든 접미사를 **압축된 Trie 형태**로 저장한 트리 구조        |

### 📦 Suffix Array (접미사 배열)

#### 🔍 정의

**Suffix Array**는 문자열의 모든 접미사를 사전순으로 정렬한 후,
 그 **시작 인덱스만 배열 형태로 저장**한 자료구조

#### 예시:

```
S = banana

Suffixes (with index):
0: banana
1: anana
2: nana
3: ana
4: na
5: a

사전순 정렬:
a       → 5  
ana     → 3  
anana   → 1  
banana  → 0  
na      → 4  
nana    → 2  

Suffix Array = [5, 3, 1, 0, 4, 2]
```

### 🔧 시간복잡도

| 알고리즘         | 복잡도        |
| ---------------- | ------------- |
| naive (정렬)     | O(n² log n)   |
| **Doubling**     | O(n log² n)   |
| **Skew / SA-IS** | O(n) (이론상) |

### ⚡ 주요 활용

| 문제/기능            | 설명                                |
| -------------------- | ----------------------------------- |
| 서브스트링 존재 확인 | 이진 탐색으로 `O(log n)`            |
| k번째 사전순 접미사  | SA[k] 확인                          |
| **LCP 배열** 생성    | 인접 접미사의 공통 접두사 길이 저장 |
| 반복 패턴 탐지       | LCP 배열로 찾음                     |
| 사전순 순서 비교     | SA로 처리 가능                      |

### 🧠 LCP 배열 (Longest Common Prefix)

- LCP[i] = `SA[i]`와 `SA[i-1]`의 접두사 공통 길이

```
S = banana
SA = [5, 3, 1, 0, 4, 2]
Suffixes:
a
ana
anana
banana
na
nana

LCP = [_, 1, 3, 0, 0, 2]
```

### 🌳 Suffix Tree (접미사 트리)

#### 📌 정의

**Suffix Tree**는 문자열의 모든 접미사를 Trie(접두사 트리)로 구성한 구조에서
 **연속된 문자들을 압축하여 공간을 줄인** 자료구조.

> 접미사 트리 = 문자열 검색용 Trie의 최적화된 압축판

#### 🌿 구조 예시 (S = banana$)

```
트리 구조 (간단히 표현):

root
 ├─ b → a → n → a → n → a → $
 ├─ a → n → a → n → a → $
 ├─ n → a → n → a → $
 ...
```

- 각 리프는 접미사의 시작 인덱스를 가짐
- 내부 노드는 공통 접두사를 표현

### 🔧 시간복잡도

| 작업                | 복잡도                       |
| ------------------- | ---------------------------- |
| 트리 생성           | O(n) (Ukkonen 알고리즘 기준) |
| 서브스트링 검색     | O(m) (m은 패턴 길이)         |
| LCP, longest repeat | O(n)                         |
| k번째 접미사 검색   | O(k)                         |

### ⚠️ 공간 차이

| 구조         | 공간                   |
| ------------ | ---------------------- |
| Suffix Array | O(n) (작음)            |
| Suffix Tree  | O(n)~O(n log n) (많음) |

Suffix Array는 메모리 적고, 구현 간단
 Suffix Tree는 메모리 크지만 서브스트링 구조 파악에 강력

### 🆚 Suffix Array vs Suffix Tree

| 항목             | Suffix Array           | Suffix Tree                    |
| ---------------- | ---------------------- | ------------------------------ |
| 저장 정보        | 접미사 시작 인덱스     | 문자 경로로 표현한 접미사 트리 |
| 공간             | 적음 (O(n))            | 큼 (O(n log n))                |
| 구현 난이도      | 보통                   | 매우 어려움 (Ukkonen 등)       |
| 검색 속도        | O(m log n) (이진 탐색) | O(m)                           |
| 반복 패턴 분석   | LCP 배열로 가능        | 더 직관적                      |
| 사전순 순서 확인 | 즉시 가능              | 복잡함                         |

### 📚 활용 분야

| 분야            | 활용                                  |
| --------------- | ------------------------------------- |
| 서브스트링 검색 | 패턴 포함 여부 (`abc` in `banana`)    |
| 사전순 비교     | 접미사 정렬 문제, k번째 사전순 접미사 |
| LCP 기반 문제   | 반복, 회문, 유사 문자열 분석          |
| 압축            | LZ77, BWT 등                          |
| 유전체 분석     | DNA 서열 패턴 추출                    |

### ✅ 정리 요약

| 개념         | 설명                                    |
| ------------ | --------------------------------------- |
| Suffix Array | 문자열 접미사를 정렬한 인덱스 배열      |
| Suffix Tree  | 접미사를 트리로 표현한 압축된 Trie 구조 |
| 시간복잡도   | O(n log² n) / O(n) 생성 가능            |
| 용도         | 검색, 반복 패턴, 압축 등                |
| 주의         | Tree는 구현/메모리 부담 큼              |

## Aho-Corasick 자동화

### 📌 1. 문제 정의

> **패턴 집합 {P₁, P₂, ..., Pₖ}와 텍스트 T가 주어졌을 때,**
>  **모든 패턴의 등장 위치를 효율적으로 찾아라.**

### 🧠 2. 핵심 아이디어

Aho-Corasick는 다음 3가지를 결합한 구조야:

| 구조         | 설명                                          |
| ------------ | --------------------------------------------- |
| Trie         | 여러 패턴을 공통 접두사 구조로 표현           |
| Failure 링크 | KMP처럼 실패 시 다음으로 점프할 위치          |
| Output 링크  | 현재 노드에서 끝나는(또는 포함된) 패턴 리스트 |

### 🏗️ 3단계 구성

#### ✅ 1단계: Trie 생성

- 모든 패턴 문자열을 Trie에 삽입
- 각 노드는 문자, 자식, isEnd 속성을 가짐

#### ✅ 2단계: Failure 링크 구성 (BFS)

- 실패 시 돌아갈 노드 지정 (접두사 일치 실패 시 KMP처럼)
- 루트의 자식은 실패 링크가 루트
- 내부 노드는 부모의 실패 링크 + 자기 글자로 연결된 노드

#### ✅ 3단계: 텍스트 검색

- 문자를 따라 이동하며,
- 매칭되지 않으면 실패 링크 따라 이동
- 일치 노드마다 output 리스트 확인 → 정답 기록

### 🔧 C++ 스타일 예제 코드 (간단 버전)

```
struct TrieNode {
    TrieNode* next[26] = {};
    TrieNode* fail = nullptr;
    vector<int> output;  // 일치한 패턴 인덱스들
};

TrieNode* root = new TrieNode();

void insert(const string& word, int idx) {
    TrieNode* node = root;
    for (char c : word) {
        int x = c - 'a';
        if (!node->next[x]) node->next[x] = new TrieNode();
        node = node->next[x];
    }
    node->output.push_back(idx);
}
```

#### 🔁 Failure 링크 구성

```
void buildFailureLinks() {
    queue<TrieNode*> q;
    root->fail = root;
    for (int c = 0; c < 26; ++c) {
        if (root->next[c]) {
            root->next[c]->fail = root;
            q.push(root->next[c]);
        } else {
            root->next[c] = root;  // 트릭: 없는 경우 루트로 연결
        }
    }

    while (!q.empty()) {
        TrieNode* cur = q.front(); q.pop();
        for (int c = 0; c < 26; ++c) {
            TrieNode* child = cur->next[c];
            if (!child) continue;

            TrieNode* f = cur->fail;
            while (!f->next[c]) f = f->fail;
            child->fail = f->next[c];

            // fail 경로 따라가며 output도 이어받기
            child->output.insert(
                child->output.end(),
                child->fail->output.begin(),
                child->fail->output.end()
            );

            q.push(child);
        }
    }
}
```

#### 🔍 텍스트 검색

```
void search(const string& text, vector<vector<int>>& matchPos) {
    TrieNode* node = root;
    for (int i = 0; i < text.size(); ++i) {
        int x = text[i] - 'a';
        while (!node->next[x]) node = node->fail;
        node = node->next[x];
        for (int patIdx : node->output)
            matchPos[patIdx].push_back(i);  // 위치 기록
    }
}
```

### ⏱️ 시간 복잡도

| 단계         | 시간                                |
| ------------ | ----------------------------------- |
| Trie 구성    | O(Σ 패턴 길이)                      |
| Failure 링크 | O(Σ 패턴 길이)                      |
| 텍스트 탐색  | O(N + 총 매칭 수) (N = 텍스트 길이) |

### 📚 실전 문제 예시

| 유형                              | 설명 |
| --------------------------------- | ---- |
| 다수 키워드 탐색 (`in` 쿼리)      | ✅    |
| 금지 단어 필터링 (`bad words`)    | ✅    |
| 바이러스 서명 탐색                | ✅    |
| 스팸 탐지, 침해 탐지 시스템(NIDS) | ✅    |
| 패턴 일치 개수/위치 찾기          | ✅    |

### 🆚 Aho-Corasick vs KMP/Z

| 항목        | Aho-Corasick        | KMP / Z        |
| ----------- | ------------------- | -------------- |
| 패턴 수     | 수천 개 이상 가능   | 보통 1개       |
| 전처리 대상 | 모든 패턴           | 단일 패턴      |
| 탐색 대상   | 전체 텍스트         | 전체 텍스트    |
| 성능        | O(N + 총 패턴 길이) | O(N + M)       |
| 사용 상황   | 다중 검색 필요 시   | 단일 패턴 검색 |

### ✅ 정리 요약

| 항목       | 설명                                          |
| ---------- | --------------------------------------------- |
| 목적       | **다수의 문자열 패턴을 동시에 검색**          |
| 구조       | Trie + Failure Link                           |
| 시간복잡도 | O(N + 총 패턴 길이 + 매칭 수)                 |
| 특징       | 선형 시간, 트리 기반 자동화                   |
| 주요 활용  | 검색 엔진, 금지어 탐지, 바이러스 패턴 탐지 등 |

# 3.4 수학적 알고리즘

## 소수 판별 및 에라토스테네스의 체

### 📌 1. 소수(Prime Number)란?

> 1보다 큰 자연수 중에서, **1과 자기 자신만을 약수로 가지는 수**

- 예: 2, 3, 5, 7, 11, 13, ...
- 1은 소수가 아님
- 2는 유일한 짝수 소수

### ✅ 2. 소수 판별 (Primality Test)

#### 방법 1: 일반 소수 판별 (Trial Division)

```
bool isPrime(int n) {
    if (n < 2) return false;
    for (int i = 2; i * i <= n; ++i)
        if (n % i == 0) return false;
    return true;
}
```

- **시간복잡도**: O(√n)
- **특징**: 간단하고 범용

#### 방법 2: 6k ± 1 최적화

- 소수는 대부분 `6k ± 1` 형태이므로, 2와 3은 미리 제외 후, 6씩 건너뛰며 검사

```
bool isPrime(int n) {
    if (n < 2) return false;
    if (n <= 3) return true;
    if (n % 2 == 0 || n % 3 == 0) return false;
    for (int i = 5; i * i <= n; i += 6)
        if (n % i == 0 || n % (i + 2) == 0) return false;
    return true;
}
```

### 🧠 3. 에라토스테네스의 체 (Sieve of Eratosthenes)

> **1부터 N까지의 모든 소수를 구하는 가장 대표적인 알고리즘**

#### 🏗️ 알고리즘 원리

1. 2부터 N까지 배열을 만든다
2. 2부터 시작해서 **자기 배수를 모두 지움**
3. 남은 수는 모두 소수

#### ✅ 코드 (C++)

```
vector<bool> isPrime(int N) {
    vector<bool> prime(N + 1, true);
    prime[0] = prime[1] = false;

    for (int i = 2; i * i <= N; ++i) {
        if (!prime[i]) continue;
        for (int j = i * i; j <= N; j += i)
            prime[j] = false;
    }
    return prime;
}
```

#### 🧮 시간복잡도

- **O(N log log N)**
- 매우 빠름, `10^7` 이하 범위는 거의 실시간 처리 가능

### 💡 확장: 소인수 분해용 최소 소인수 테이블

```
vector<int> minFactor(N + 1);

void sieveMinFactor(int N) {
    for (int i = 2; i <= N; ++i) {
        if (minFactor[i] == 0) {
            for (int j = i; j <= N; j += i)
                if (minFactor[j] == 0)
                    minFactor[j] = i;
        }
    }
}
```

> `minFactor[n]`을 이용해 O(log n)에 소인수 분해 가능

### 🧠 실제 문제 활용 예시

| 문제 유형              | 소수 판별 | 에라토스테네스     |
| ---------------------- | --------- | ------------------ |
| 단일 숫자 판별         | ✅         | ❌                  |
| 구간 내 모든 소수 출력 | ❌         | ✅                  |
| 소인수 분해            | ❌         | ✅ (with minFactor) |
| 골드바흐 추측          | ✅         | ✅                  |
| 소수의 조합, 쌍 판별   | ✅         | ✅                  |

### 🧪 예제 문제 (BOJ 기준)

| 문제 이름           | 번호 | 관련 알고리즘 |
| ------------------- | ---- | ------------- |
| 소수 찾기           | 1978 | 소수 판별     |
| 골드바흐의 추측     | 9020 | 체 + 판별     |
| 에라토스테네스의 체 | 2960 | 체 구현       |
| 소수 구하기         | 1929 | 체            |
| 거의 소수           | 1456 | 체 변형       |

### ✅ 정리 요약

| 항목        | 설명                                            |
| ----------- | ----------------------------------------------- |
| 소수 판별   | O(√n), 단일 수 확인                             |
| 체 알고리즘 | O(n log log n), 다수 소수 빠르게 탐색           |
| 확장        | 최소 소인수, 조합 탐색, 소수 구간 응용          |
| 실전 사용   | 암호학, 수론 문제, 조합 필터링, 소수 쌍 탐색 등 |

## 최대공약수(GCD), 유클리드 알고리즘

### 📌 1. 최대공약수(GCD: Greatest Common Divisor)

> 두 수 A, B의 공약수 중 **가장 큰 정수**

- 예: GCD(12, 18) = 6
- 성질:
  - GCD(A, A) = A
  - GCD(A, 0) = A
  - GCD(0, B) = B
  - GCD(A, B) = GCD(B, A)

### 🔁 2. 유클리드 알고리즘

> “**큰 수에서 작은 수를 계속 나눠서** 나머지가 0이 될 때의 수가 GCD다.”

#### 🎯 핵심 공식:

```
GCD(A, B) = GCD(B, A % B)
```

→ A를 B로 나눈 나머지를 계속 대입해 나가다 보면, 언젠가는 0이 되고, 그때의 B가 최대공약수!

#### ✅ 반복문 구현 (C++)

```
int gcd(int a, int b) {
    while (b != 0) {
        int r = a % b;
        a = b;
        b = r;
    }
    return a;
}
```

#### ✅ 재귀형 구현

```
int gcd(int a, int b) {
    return b == 0 ? a : gcd(b, a % b);
}
```

#### 📊 시간복잡도

- O(log(max(A, B)))
- 매우 빠르며 64비트 정수도 문제 없음

### ➕ 3. 최소공배수(LCM)와의 관계

> 두 수의 최소공배수는 GCD를 이용해서 쉽게 구할 수 있어

#### 공식:

```
LCM(A, B) = A × B / GCD(A, B)
```

#### 예:

```
int lcm(int a, int b) {
    return a / gcd(a, b) * b;
}
```

### 🧠 4. 확장 유클리드 알고리즘 (Extended Euclidean Algorithm)

> **ax + by = gcd(a, b)** 를 만족하는 정수 x, y를 구한다

→ **선형 합동 방정식, 모듈러 역원**에서 매우 중요

#### ✅ 구현 예:

```
int extendedGCD(int a, int b, int& x, int& y) {
    if (b == 0) { x = 1; y = 0; return a; }
    int x1, y1;
    int g = extendedGCD(b, a % b, x1, y1);
    x = y1;
    y = x1 - (a / b) * y1;
    return g;
}
```

- 결과: `ax + by = gcd(a, b)` 를 만족하는 x, y 반환됨

### 📚 GCD 사용 실전 문제 예시

| 문제 유형                          | GCD/유클리드 활용      |
| ---------------------------------- | ---------------------- |
| 수열 전체의 최대공약수 구하기      | ✅ O(N log A)           |
| A와 B의 최소 공배수 구하기         | ✅ GCD로 LCM 계산       |
| 기약 분수/약분 처리                | ✅ 분자/분모 GCD 나누기 |
| 나머지 연산 역원 (modular inverse) | ✅ 확장 유클리드 이용   |
| 중국인의 나머지 정리 (CRT)         | ✅ 계수의 GCD 사용      |

### 💬 인터뷰/시험 질문

- 유클리드 알고리즘이 종료되는 이유는?
- 재귀보다 반복문이 더 안전한 이유는?
- 확장 유클리드가 필요한 문제는 어떤 것?
- GCD가 1이라는 건 어떤 의미인가?

### ✅ 정리 요약

| 항목          | 설명                                   |
| ------------- | -------------------------------------- |
| GCD 정의      | 두 수의 공약수 중 최대값               |
| 유클리드 공식 | GCD(A, B) = GCD(B, A % B)              |
| 시간복잡도    | O(log A)                               |
| 응용          | LCM, 약분, 모듈러 연산, 정수 해 구하기 |
| 확장 버전     | ax + by = GCD(a, b) 만족하는 x, y 구함 |

## 모듈러 산술, 거듭제곱, 역원

### 📘 1. 모듈러 산술 (Modular Arithmetic)

> "정수 연산에서 나머지를 기준으로 하는 계산 체계"

#### ✨ 기본 정의

```
a ≡ b mod m  ⇔  (a - b)가 m의 배수이다
```

#### 📌 모듈러 연산의 성질

| 연산     | 성질                                          |
| -------- | --------------------------------------------- |
| 덧셈     | (a + b) mod m = (a mod m + b mod m) mod m     |
| 뺄셈     | (a - b) mod m = (a mod m - b mod m + m) mod m |
| 곱셈     | (a × b) mod m = (a mod m × b mod m) mod m     |
| 나눗셈 ❗ | **불가능함!** → → 반드시 `모듈러 역원` 필요   |

#### 예시

```
(17 + 23) % 5 = 40 % 5 = 0
(17 * 23) % 5 = (2 * 3) % 5 = 6 % 5 = 1
```

### 📗 2. 모듈러 거듭제곱 (Modular Exponentiation)

> `(a^b) % m`을 **빠르게** 계산하는 방법
>  반복 제곱법(Pow-by-Squaring) 사용

#### ✅ 반복 제곱법 코드 (O(log b))

```
long long modPow(long long a, long long b, long long m) {
    long long res = 1;
    a %= m;
    while (b > 0) {
        if (b & 1) res = res * a % m;
        a = a * a % m;
        b >>= 1;
    }
    return res;
}
```

#### 예시

```
(3^13) % 7 = ?
→ 계산 과정:
3^1 = 3
3^2 = 9 % 7 = 2
3^4 = 2^2 = 4
3^8 = 4^2 = 16 % 7 = 2

→ 최종 = (3^8) * (3^4) * (3^1) = 2 * 4 * 3 = 24 % 7 = 3
```

### 📙 3. 모듈러 역원 (Modular Inverse)

> 나눗셈 `a / b mod m`을 계산하려면
>  `b^-1 mod m`을 먼저 구해야 함

#### ✅ 정의

```
b^-1 ≡ x (mod m) such that (b * x) % m == 1
```

#### 📌 조건

- `b`와 `m`이 **서로소(GCD(b, m) == 1)** 여야만 역원이 존재한다

#### 방법 1️⃣: **확장 유클리드 알고리즘**

```
long long extendedGCD(long long a, long long b, long long &x, long long &y) {
    if (b == 0) { x = 1; y = 0; return a; }
    long long x1, y1;
    long long g = extendedGCD(b, a % b, x1, y1);
    x = y1;
    y = x1 - (a / b) * y1;
    return g;
}

long long modInverse(long long a, long long m) {
    long long x, y;
    long long g = extendedGCD(a, m, x, y);
    if (g != 1) return -1; // 역원 존재 안 함
    return (x % m + m) % m;
}
```

#### 방법 2️⃣: **페르마의 소정리** (m이 소수일 때만)

> ```
> a^(m-2) ≡ a^-1 mod m
> ```

```
long long modInverseFermat(long long a, long long m) {
    return modPow(a, m - 2, m);
}
```

### ✅ 예시

```
// (12 / 5) % 17
long long a = 12, b = 5, m = 17;
long long b_inv = modInverse(b, m);
long long result = a * b_inv % m;  // = 12 * 7 % 17 = 16
```

### 📚 응용

| 응용 사례                  | 설명                  |
| -------------------------- | --------------------- |
| 조합 nCr % p               | 팩토리얼 역원 필요    |
| 모듈러 나눗셈              | a / b ≡ a * b⁻¹ mod m |
| RSA 복호화 키 d 계산       | e⁻¹ mod φ(n)          |
| 중국인의 나머지 정리 (CRT) | M_i^-1 mod m 필요     |

### ✅ 요약 정리

| 항목             | 내용                                           |
| ---------------- | ---------------------------------------------- |
| 모듈러 산술      | mod 연산 성질 활용                             |
| 거듭제곱         | `O(log b)` 반복 제곱법                         |
| 역원 조건        | GCD(a, m) = 1일 때만                           |
| 역원 계산 방법   | 확장 유클리드, 페르마 소정리 (mod가 소수일 때) |
| 나눗셈 계산 방법 | `a / b ≡ a * b⁻¹ mod m`                        |

## 조합론(Combinatorics), 동적 테이블 기반

### 📌 1. 조합의 기본 정의

> "n개의 원소 중에서 r개를 **순서 없이** 고르는 경우의 수"

```
C(n, r) = n! / (r! * (n - r)!)
```

하지만 팩토리얼 계산은 값이 크고, 나눗셈은 **mod 연산에서 위험함**
 → 그래서 우리는 **동적 테이블 방식**으로 접근함.

### 🧠 2. 파스칼의 삼각형(Pascal's Triangle) 재귀 관계

```
C(n, r) = C(n - 1, r - 1) + C(n - 1, r)
```

- 의미:
  - `r번째 항을 고르는 경우` + `안 고르는 경우`
- 기저 조건:
  - `C(n, 0) = C(n, n) = 1`

### 📦 3. DP 테이블 기반 구현

#### ✅ C++ 버전 (최대 n까지 모든 조합 계산)

```
const int MAX = 1001;
int comb[MAX][MAX];
const int MOD = 1e9 + 7;

void buildComb() {
    for (int n = 0; n < MAX; ++n) {
        comb[n][0] = comb[n][n] = 1;
        for (int r = 1; r < n; ++r) {
            comb[n][r] = (comb[n-1][r-1] + comb[n-1][r]) % MOD;
        }
    }
}
```

- **시간복잡도**: O(n²)
- **메모리복잡도**: O(n²)
- `comb[n][r]` = C(n, r) % MOD

### 🔧 4. 메모리 최적화 (1차원 DP)

> 같은 행만 필요하므로 **1차원 배열**로도 가능
>  (역순으로 갱신)

```
int comb[MAX];
comb[0] = 1;
for (int n = 1; n <= N; ++n) {
    for (int r = n; r >= 1; --r) {
        comb[r] = (comb[r] + comb[r - 1]) % MOD;
    }
}
```

### 🔢 5. 조합론 관련 문제 유형

| 유형                      | 접근 방식                         |
| ------------------------- | --------------------------------- |
| 경로 수 (오른쪽, 아래만)  | C(n + m, n)                       |
| 이항 계수                 | DP 또는 페르마 기반               |
| 나누어 떨어지지 않게 배치 | Inclusion-Exclusion               |
| 문자열 개수 조합          | DP with 조합                      |
| n개의 숫자 합이 k         | DP[n][k] = DP[n][k - i] + ...     |
| 파티션, 정수 분할         | p(n, k) = p(n-1, k-1) + p(n-k, k) |

### 🎯 6. nCr % p 계산 (p는 소수)

> DP 테이블 대신 **팩토리얼 & 역원**을 사전 계산해서도 가능

#### 팩토리얼 사전 계산 + 모듈러 역원

```
long long fact[MAX], inv[MAX];

void initFactorials(int N) {
    fact[0] = 1;
    for (int i = 1; i <= N; ++i)
        fact[i] = fact[i - 1] * i % MOD;
    
    inv[N] = modPow(fact[N], MOD - 2, MOD);
    for (int i = N - 1; i >= 0; --i)
        inv[i] = inv[i + 1] * (i + 1) % MOD;
}

long long nCr(int n, int r) {
    if (r < 0 || r > n) return 0;
    return fact[n] * inv[r] % MOD * inv[n - r] % MOD;
}
```

- 시간복잡도: O(1) per query after O(N) precomputation
- 매우 빠름, 대형 문제에서 많이 사용됨

### 💡 7. 실전 예시

| 문제 유형                    | 조합 적용 예              |
| ---------------------------- | ------------------------- |
| 두 집합의 교집합 개수 계산   | Inclusion-Exclusion       |
| 색칠, 배치, 앉기             | 조합 or 순열              |
| 회전대칭 제거                | 조합 / 순열 - 고정점 제거 |
| 이항 정리, 다항 계수         | nCr * a^r * b^(n - r)     |
| 특정 조건에 따른 구분 나누기 | 조합 + DP                 |

### 🧠 인터뷰 질문 대비

- 조합을 O(1)에 구하는 방법은?
- nCr % p가 왜 모듈러 역원을 사용하나?
- 조합이 2차원 DP가 가능한 이유는?
- nCr = nC(n-r) 이 성립하는 이유는?

### ✅ 정리 요약

| 항목        | 설명                                      |
| ----------- | ----------------------------------------- |
| 정의        | n개 중 r개를 고르는 경우의 수             |
| DP 재귀식   | C(n, r) = C(n-1, r-1) + C(n-1, r)         |
| 구현 방식   | 2차원 테이블, 1차원 최적화, 팩토리얼 방식 |
| 모듈러 연산 | % p 계산 시 역원 필요                     |
| 시간복잡도  | O(n²) or O(1) (사전 계산 후)              |
| 활용 분야   | 경로, 배치, 나눗셈, 암호학, 수학 등       |

